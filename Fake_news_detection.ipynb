{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/asdfasdasd314/satire-news-detector/blob/main/Fake_news_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SqPCfnLkuxpb",
        "outputId": "0b380d78-eadf-4b33-9c7e-c5162ce2e7de"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting scikeras\n",
            "  Downloading scikeras-0.13.0-py3-none-any.whl.metadata (3.1 kB)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from scikeras) (3.8.0)\n",
            "Requirement already satisfied: scikit-learn>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from scikeras) (1.6.1)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->scikeras) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->scikeras) (2.0.2)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->scikeras) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->scikeras) (0.1.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->scikeras) (3.14.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->scikeras) (0.16.0)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->scikeras) (0.4.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->scikeras) (25.0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.4.2->scikeras) (1.15.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.4.2->scikeras) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.4.2->scikeras) (3.6.0)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from optree->keras>=3.2.0->scikeras) (4.14.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.2.0->scikeras) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.2.0->scikeras) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->scikeras) (0.1.2)\n",
            "Downloading scikeras-0.13.0-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: scikeras\n",
            "Successfully installed scikeras-0.13.0\n",
            "Collecting scikit-learn==1.5.2\n",
            "  Downloading scikit_learn-1.5.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.5.2) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.5.2) (1.15.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.5.2) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.5.2) (3.6.0)\n",
            "Downloading scikit_learn-1.5.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m88.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: scikit-learn\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.6.1\n",
            "    Uninstalling scikit-learn-1.6.1:\n",
            "      Successfully uninstalled scikit-learn-1.6.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "umap-learn 0.5.9.post2 requires scikit-learn>=1.6, but you have scikit-learn 1.5.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed scikit-learn-1.5.2\n"
          ]
        }
      ],
      "source": [
        "!pip install scikeras\n",
        "!pip install scikit-learn==1.5.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-BQEZDZo2kn2"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zEJ84wfGD2ax"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import string\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import spacy # Potentially leave this out\n",
        "import tensorflow as tf\n",
        "# import sklearn\n",
        "from sklearn.model_selection import train_test_split, cross_val_predict\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from scikeras.wrappers import KerasClassifier\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oZvCXFEAurg5"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"/content/drive/MyDrive/onion/OnionOrNot.csv\")\n",
        "\n",
        "# Drop 6000 random rows to check if there is a problem with unbalanced data\n",
        "# class_0 = df[df['label'] == 0]\n",
        "\n",
        "# to_drop = class_0.sample(n=6000, random_state=42)\n",
        "\n",
        "# df_reduced = df.drop(to_drop.index)\n",
        "# df = df_reduced\n",
        "# -------------------------------------------------------------------------\n",
        "\n",
        "df.head()\n",
        "df.columns\n",
        "df['label'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "heS4XPW1js7s"
      },
      "outputs": [],
      "source": [
        "X = df[\"text\"]\n",
        "y = df[\"label\"]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kK0feImpWfwo"
      },
      "outputs": [],
      "source": [
        "nlp = spacy.load(\"en_core_web_sm\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FYduRWysvLPB"
      },
      "outputs": [],
      "source": [
        "X = df['text']\n",
        "y = df['label']\n",
        "\n",
        "def get_nlps(data: pd.Series):\n",
        "  copy = data.copy()\n",
        "  return copy.apply(lambda x: nlp(x))\n",
        "\n",
        "def count_pronouns(data: pd.Series):\n",
        "  copy = data.copy()\n",
        "  return copy.apply(lambda x: len([ent.label_ for ent in x.ents if ent.label_ in [\"PERSON\", \"ORG\", \"GPE\"]]))\n",
        "\n",
        "def count_people(data: pd.Series):\n",
        "  copy = data.copy()\n",
        "  return copy.apply(lambda x: len([ent.text for ent in x.ents if ent.label_ == \"PERSON\"]))\n",
        "\n",
        "def count_orgs(data: pd.Series):\n",
        "  copy = data.copy()\n",
        "  return copy.apply(lambda x: len([ent.text for ent in x.ents if ent.label_ == \"ORG\"]))\n",
        "\n",
        "def count_gpes(data: pd.Series):\n",
        "  copy = data.copy()\n",
        "  return copy.apply(lambda x: len([ent.text for ent in x.ents if ent.label_ == \"GPE\"]))\n",
        "\n",
        "def count_verbs(data: pd.Series):\n",
        "  copy = data.copy()\n",
        "  return copy.apply(lambda x: len([token for token in x if token.pos_ == \"VERB\"]))\n",
        "\n",
        "def count_auxiliaries(data: pd.Series):\n",
        "  copy = data.copy()\n",
        "  return copy.apply(lambda x: len([token for token in x if token.pos_ == \"AUX\"]))\n",
        "\n",
        "def count_adjectives(data: pd.Series):\n",
        "  copy = data.copy()\n",
        "  return copy.apply(lambda x: len([token for token in x if token.pos_ == \"ADJ\"]))\n",
        "\n",
        "def count_characters(data: pd.Series):\n",
        "  copy = data.copy()\n",
        "  return copy.apply(lambda x: len(x))\n",
        "\n",
        "def count_tokens(data: pd.Series):\n",
        "  copy = data.copy()\n",
        "  return copy.apply(lambda x: len([ent.text for ent in x.ents]))\n",
        "\n",
        "def count_exclamation(data:pd.Series):\n",
        "  copy = data.copy()\n",
        "  return copy.apply(lambda x: len([token for token in x if token.pos_ == \"!\"]))\n",
        "\n",
        "def count_quotes(data: pd.Series):\n",
        "  copy = data.copy()\n",
        "  return copy.apply(lambda x: len([token for token in x if token.pos_ == \"'\"]))\n",
        "def count_question_marks(data: pd.Series):\n",
        "  copy = data.cpoy()\n",
        "  return copy.apply(lambda x: len([token for token in x if token.pos == \"?\"]))\n",
        "\n",
        "def vectorizer_preprocessor(text):\n",
        "    text = text.lower()\n",
        "    text = regex.sub('', text)  # remove unwanted punctuation\n",
        "    return text\n",
        "\n",
        "punct_to_remove = string.punctuation.replace('\"', '').replace(',', '')\n",
        "regex = re.compile(f\"[{re.escape(punct_to_remove)}]\")\n",
        "\n",
        "# Token pattern: allow words with apostrophes (like don't), quotes, and commas\n",
        "# This pattern:\n",
        "# - Matches words with optional internal apostrophes, commas, and double quotes\n",
        "# - E.g., it keeps: don't, \"hello\", new,york\n",
        "token_pattern = r'\\b[a-zA-Z0-9\"\\',]{2,}\\b'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ogzqimtBvmx8"
      },
      "outputs": [],
      "source": [
        "X_train_text, X_test_text, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "vectorizer = CountVectorizer(stop_words=\"english\", preprocessor=vectorizer_preprocessor, token_pattern=token_pattern)\n",
        "vectorizer.fit_transform(X_train_text)\n",
        "\n",
        "X_train_nlps, X_test_nlps = get_nlps(X_train_text), get_nlps(X_test_text)\n",
        "\n",
        "count_vector = CountVectorizer()\n",
        "bag = count_vector.fit_transform(df).toarray()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "oM9oKaBt1Vj5",
        "outputId": "01cacbcc-4095-434d-e495-917739798163"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'count_pronouns' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1-3750056751.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_train_pronouns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test_pronouns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcount_pronouns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_nlps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount_pronouns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_nlps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mX_train_people\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test_people\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcount_people\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_nlps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount_people\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_nlps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mX_train_orgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test_orgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcount_orgs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_nlps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount_orgs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_nlps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mX_train_gpes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test_gpes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcount_gpes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_nlps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount_gpes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_nlps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mX_train_verbs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test_verbs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcount_verbs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_nlps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount_verbs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_nlps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'count_pronouns' is not defined"
          ]
        }
      ],
      "source": [
        "X_train_pronouns, X_test_pronouns = count_pronouns(X_train_nlps), count_pronouns(X_test_nlps)\n",
        "X_train_people, X_test_people = count_people(X_train_nlps), count_people(X_test_nlps)\n",
        "X_train_orgs, X_test_orgs = count_orgs(X_train_nlps), count_orgs(X_test_nlps)\n",
        "X_train_gpes, X_test_gpes = count_gpes(X_train_nlps), count_gpes(X_test_nlps)\n",
        "X_train_verbs, X_test_verbs = count_verbs(X_train_nlps), count_verbs(X_test_nlps)\n",
        "X_train_auxiliaries, X_test_auxiliaries = count_auxiliaries(X_train_nlps), count_auxiliaries(X_test_nlps)\n",
        "X_train_adjectives, X_test_adjectives = count_adjectives(X_train_nlps), count_adjectives(X_test_nlps)\n",
        "X_train_characters, X_test_characters = count_characters(X_train_text), count_characters(X_test_text)\n",
        "X_train_tokens, X_test_tokens = count_tokens(X_train_nlps), count_tokens(X_test_nlps)\n",
        "X_train_exclamation, X_test_exclamation = count_exclamation(X_train_nlps), count_exclamation(X_train_nlps)\n",
        "X_train_quotes, X_test_quotes = count_quotes(X_train_nlps), count_qoutes(X_train_nlps)\n",
        "X_train_questions_marks, X_test_question_marks = count_question_marks(X_train_nlps), count_question_marks(X_train_nlps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pXwP7So8v42n"
      },
      "outputs": [],
      "source": [
        "train_df = pd.DataFrame({\n",
        "    'text': X_train_text,\n",
        "    'num_pronouns': X_train_pronouns,\n",
        "    'num_characters': X_train_characters,\n",
        "    'num_tokens': X_train_tokens,\n",
        "    'num_verbs': X_train_verbs,\n",
        "    'num_auxiliaries': X_train_auxiliaries,\n",
        "    'num_adjectives': X_train_adjectives,\n",
        "    'num_people': X_train_people,\n",
        "    'num_orgs': X_train_orgs,\n",
        "    'num_gpes': X_train_gpes,\n",
        "    'num_exclamation': X_train_exclamation,\n",
        "    'num_quotes': X_train_quotes,\n",
        "    'num_question_makrs': X_test_question_marks,\n",
        "    'label': y_train\n",
        "})\n",
        "\n",
        "test_df = pd.DataFrame({\n",
        "    'text': X_test_text,\n",
        "    'num_pronouns': X_test_pronouns,\n",
        "    'num_characters': X_test_characters,\n",
        "    'num_tokens': X_test_tokens,\n",
        "    'num_verbs': X_test_verbs,\n",
        "    'num_auxiliaries': X_test_auxiliaries,\n",
        "    'num_adjectives': X_test_adjectives,\n",
        "    'num_people': X_test_people,\n",
        "    'num_orgs': X_test_orgs,\n",
        "    'num_gpes': X_test_gpes,\n",
        "    'num_exclamation': X_test_exclamation,\n",
        "    'num_quotes': X_test_quotes\n",
        "    'num_question_marks': X_test_question_marks\n",
        "    'label': y_test\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uihcdECCrb5J"
      },
      "outputs": [],
      "source": [
        "num_features = len(vectorizer.vocabulary_) + train_df.shape[1] - 2\n",
        "\n",
        "def make_model():\n",
        "    model = keras.Sequential([\n",
        "        layers.Input(shape=(num_features,)),\n",
        "        layers.Dense(32, activation='relu'),\n",
        "        layers.Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[\"accuracy\"])\n",
        "    return model\n",
        "\n",
        "# ColumnTransformer to handle different types of features\n",
        "preprocessor = ColumnTransformer(\n",
        "    [\n",
        "      ('tfidf', vectorizer, 'text'),\n",
        "      ('scaler', StandardScaler(), ['num_pronouns', 'num_characters', 'num_tokens', 'num_verbs', 'num_auxiliaries', 'num_adjectives', 'num_people', 'num_orgs', 'num_gpes', 'num_exclamation', 'num_quotes', 'num_question_marks']),  # scale numeric features\n",
        "    ],\n",
        "  )\n",
        "\n",
        "# Combine with estimator\n",
        "pipeline = Pipeline([\n",
        "    ('features', preprocessor),\n",
        "    ('classifier', KerasClassifier(model=make_model, epochs=2, batch_size=32))\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iED_NjCxv11Q"
      },
      "outputs": [],
      "source": [
        "pipeline.fit(train_df.drop(columns=['label']), train_df['label'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C_rrDG9NvwlY"
      },
      "outputs": [],
      "source": [
        "y_pred = pipeline.predict(test_df.drop(columns=['label']))\n",
        "\n",
        "print(accuracy_score(test_df['label'], y_pred))\n",
        "print(precision_score(test_df['label'], y_pred))\n",
        "print(recall_score(test_df['label'], y_pred))\n",
        "print(confusion_matrix(test_df['label'], y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "07xS-tvdSvPr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "e9f5ddd1-6424-4b62-b3ba-601fe00f8d97"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'df' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2-1650076279.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# wrong = df[pipeline.predict(vectorizer.transform(df['text'])) != y]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtrue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mfalse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
          ]
        }
      ],
      "source": [
        "# right = df[pipeline.predict(vectorizer.transform(df['text'])) == y]\n",
        "# wrong = df[pipeline.predict(vectorizer.transform(df['text'])) != y]\n",
        "\n",
        "true = df[df['label'] == 0]\n",
        "false = df[df['label'] == 1]\n",
        "\n",
        "# right_test = right[right['text'].isin(X_test)]\n",
        "# wrong_test = wrong[wrong['text'].isin(X_test)]\n",
        "\n",
        "# Write to CSV to investigate what is going wrong (perhaps there's a pattern?)\n",
        "# right.to_csv(\"/content/drive/MyDrive/onion/right.csv\")\n",
        "# wrong.to_csv(\"/content/drive/MyDrive/onion/wrong.csv\")\n",
        "\n",
        "# right_test.to_csv(\"/content/drive/MyDrive/onion/right_test.csv\")\n",
        "# wrong_test.to_csv(\"/content/drive/MyDrive/onion/wrong_test.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wb_ADbSbubl2"
      },
      "outputs": [],
      "source": [
        "true_nlps = get_nlps(true['text'])\n",
        "false_nlps = get_nlps(false['text'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fKY1t6XErgyu"
      },
      "outputs": [],
      "source": [
        "true_entities = count_gpes(true_nlps)\n",
        "false_entities = count_gpes(false_nlps)\n",
        "\n",
        "total_true = 0\n",
        "total_false = 0\n",
        "for i in true_entities:\n",
        "  total_true += i\n",
        "for i in false_entities:\n",
        "  total_false += i\n",
        "\n",
        "print(total_true / 15000)\n",
        "print(total_false / 9000)\n",
        "print(true_entities)\n",
        "print(false_entities)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uC5q7c90u0iW"
      },
      "source": [
        "Statistics:\n",
        "\n",
        "True articles contain 8114 proper nouns and false articles contain 6104 proper nouns\n",
        "\n",
        "True articles contain on average 0.29 mentions of GPEs and false contain 0.047 mentions (the differences in the other two types of entities are basically negligible)\n",
        "\n",
        "True articles contain on average 1.906 verbs and fake articles contain 1.744 verbs\n",
        "\n",
        "True articles contain on average 0.4084 auxiliary verbs (e.g. is, was, am) and false articles contain 0.5467 on average\n",
        "\n",
        "True articles contain on average 0.7764 adjectives and false articles contain on average 0.522 adjectives\n",
        "\n",
        "True articles are on average 71.62 characters long and false articles are on average 83.26 characters long\n",
        "\n",
        "True articles are on average 13.35 tokens long and false articles are 15.34 tokens long\n",
        "\n",
        "True articles are on average 11.69 words long and false articles are on average 13.703 words long (using `.split(' ')`)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GdYtY3YC5Yg-"
      },
      "source": [
        "These results show that there is fundamentally something in that data that allows the model to distinguish between fake news and real news reliably, although whether or not we will be able to make it to 100% is the tricky part"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YHI0wyFw6Lpm"
      },
      "source": [
        "**Potential Hypothesis**: The vectorizer we are currently using picks up on rarely used words, and Onion articles often use crazy words, for example: \"*Environmental Win: Scientists Just Cut Down The World’s Oldest Tree After It Went Over 5,000 Years Without Giving Us A Single Goddam Apple*\"\n",
        "\n",
        "So roughly 80% of the time looking for crazy words or strings of crazy words will work, whereas this (the model got it wrong): \"*ICE Sends Agents Home With Sacks Of Flour To Practice What It Like Detaining Real Baby*\" contains no crazy words and is only crazy given the relation of \"*ICE agents*\" to \"*detaining real baby*\" which maybe the model has a harder time picking up on? So potentially needing more data or something like an LLM that more easily picks up on the meanings of words in relation to each other"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iwaTQ90vOfw2"
      },
      "outputs": [],
      "source": [
        "# To test this hypothesis, look for any trends in the vectorized data\n",
        "right_vecs = vectorizer.transform(right['text'])\n",
        "wrong_vecs = vectorizer.transform(wrong['text'])\n",
        "true_vecs = vectorizer.transform(true['text'])\n",
        "false_vecs = vectorizer.transform(false['text'])\n",
        "\n",
        "right_pred_word_occurrences = pd.DataFrame(right_vecs.toarray())\n",
        "wrong_pred_word_occurrences = pd.DataFrame(wrong_vecs.toarray())\n",
        "true_pred_word_occurrences = pd.DataFrame(true_vecs.toarray())\n",
        "false_pred_word_occurrences = pd.DataFrame(false_vecs.toarray())\n",
        "\n",
        "right_vec_sums = np.sum(right_pred_word_occurrences, axis=0)\n",
        "wrong_vec_sums = np.sum(wrong_pred_word_occurrences, axis=0)\n",
        "true_vec_sums = np.sum(true_pred_word_occurrences, axis=0)\n",
        "false_vec_sums = np.sum(false_pred_word_occurrences, axis=0)\n",
        "\n",
        "lower_bound = 1\n",
        "upper_bound = 20\n",
        "\n",
        "most_frequent_rights = right_vec_sums.sort_values(ascending=False)[lower_bound:upper_bound,]\n",
        "most_frequent_wrongs = wrong_vec_sums.sort_values(ascending=False)[lower_bound:upper_bound,]\n",
        "most_frequent_trues = true_vec_sums.sort_values(ascending=False)[lower_bound:upper_bound,]\n",
        "most_frequent_falses = false_vec_sums.sort_values(ascending=False)[lower_bound:upper_bound,]\n",
        "\n",
        "# vocabulary_ maps: word → index\n",
        "vocab = vectorizer.vocabulary_\n",
        "\n",
        "# Reverse it: index → word\n",
        "idx_to_word = {index: word for word, index in vocab.items()}\n",
        "\n",
        "right_labels = pd.Series([idx_to_word[i] for i in most_frequent_rights.keys()])\n",
        "wrong_labels = pd.Series([idx_to_word[i] for i in most_frequent_wrongs.keys()])\n",
        "true_labels = pd.Series([idx_to_word[i] for i in most_frequent_trues.keys()])\n",
        "false_labels = pd.Series([idx_to_word[i] for i in most_frequent_falses.keys()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rPvfMpkVIujU"
      },
      "outputs": [],
      "source": [
        "# Create 1 row, 2 columns of subplots\n",
        "fig, axes = plt.subplots(2, 2, figsize=(10, 5))\n",
        "\n",
        "# Subplot 1\n",
        "axes[0, 0].bar(right_labels, most_frequent_rights, color='skyblue')\n",
        "axes[0, 0].set_title('Right Predictions')\n",
        "axes[0, 0].set_ylabel('Frequency')\n",
        "axes[0, 0].set_xticklabels(right_labels, rotation=50)\n",
        "\n",
        "# Subplot 2\n",
        "axes[0, 1].bar(wrong_labels, most_frequent_wrongs, color='lightgreen')\n",
        "axes[0, 1].set_title('Wrong Predictions')\n",
        "axes[0, 1].set_ylabel('Frequency')\n",
        "axes[0, 1].set_xticklabels(wrong_labels, rotation=50)\n",
        "\n",
        "# Subplot 3\n",
        "axes[1, 0].bar(true_labels, most_frequent_trues, color='yellow')\n",
        "axes[1, 0].set_title('True Headlines')\n",
        "axes[1, 0].set_ylabel('Frequency')\n",
        "axes[1, 0].set_xticklabels(true_labels, rotation=50)\n",
        "\n",
        "# Subplot 4\n",
        "axes[1, 1].bar(false_labels, most_frequent_falses, color='lightpink')\n",
        "axes[1, 1].set_title('False Headlines')\n",
        "axes[1, 1].set_ylabel('Frequency')\n",
        "axes[1, 1].set_xticklabels(false_labels, rotation=50)\n",
        "\n",
        "# Optional: Adjust layout\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U9AufcUJS1jc"
      },
      "outputs": [],
      "source": [
        "# model.predict(vectorizer.transform([\"Something Forbidden Stirs Deep Within Trump After He Sees Political Cartoon Depicting Him As Chicken\"]))\n",
        "model.predict(vectorizer.transform([\"Bold Move: Hulu Has Announced That They’re Gonna Go Ahead And Reboot ‘Shrill’ While It’s Still On Since You Idiots Will Watch Anything\"]))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}